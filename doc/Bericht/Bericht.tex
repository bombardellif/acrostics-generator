%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{reportAlternative}

%\usepackage[german]{babel}
\usepackage[utf8]{inputenc}
\usepackage{graphicx} % Required to insert images
\usepackage{float}
\usepackage{listings}
\usepackage{url}
\usepackage{alltt}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[nottoc]{tocbibind}

\settocbibname{References}

\graphicspath{ {img/} }
\bibliographystyle{plainnat}


% Margins
\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in 

\linespread{1.1} % Line spacing

%----------------------------------------------------------------------------------------
%	TITLE PAGE
%----------------------------------------------------------------------------------------

\title{
\includegraphics[scale=0.5]{tub_logo}\\
\Large{
Technische Universität Berlin\\
Fakultät IV - Fakultät Elektrotechnik und Informatik\\
Fachgebiet Datenbanksysteme und Informationsmanagement
}\\
\vspace{1.5cm}\textbf{Project Report\\
Generating Acrostics via Paraphrasing and Heuristic Search\\
DBPRO - Database Projects (WS 2014/2015)
}\\
}

\author{
\vspace{1.5cm}\\
Supervisor: \\
Johannes Kirschnick \\
\\
Authors:\\
Bruno Soares Fillmann () \\
Fernando Bombardelli da Silva (bombardelli.f@mailbox.tu-berlin.de)\\
Jürgen Bauer () \\
\vspace{2.5cm}William Bombardelli da Silva (wbombardellis@mailbox.tu-berlin.de)}

\date{February 2$^{nd}$, 2015} % Insert date here if you want it to appear below your name

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle

%----------------------------------------------------------------------------------------
%	TABLE OF CONTENTS
%----------------------------------------------------------------------------------------

%\setcounter{tocdepth}{1} % Uncomment this line if you don't want subsections listed in the ToC

%\newpage
\tableofcontents
\newpage

%----------------------------------------------------------------------------------------
% Examples of elements for the report in latex
%----------------------------------------------------------------------------------------
%================
%Inserting code:
%\lstinputlisting[frame=single, breaklines=true, language=java, label=lst:Foo, caption=Foo]{foo.java}
%================
%Inserting code inline:
%\begin{lstlisting}[frame=single, breaklines=true, language=java]
%//CODE HERE
%\end{lstlisting}
%================
%Define a label for furutre referenceing: \label{sec:Foo} 
%Refecing a label: \ref{sec:Foo}
%================
%Citing Bibliography: \cite{NameOfBibItem}
%================
%Emphasis on text: \emph{foo}
%Bold on text: \textbf{Foo}
%================
%Table Example: 
%\begin{table}[h]
%\centering
%\begin{tabular}{l | l | l | l | l}
%	\hline
%	\textbf{Modificador} & \textbf{Classe} & \textbf{Pacote} & \textbf{Subclasse} & \textbf{Mundo} \\ \hline
%		\textbf{\textit{public}} &	S &		S &	S &	S \\ \hline
%		\textbf{\textit{protected}} &	S &		S &	S &	N \\ \hline
%		\textit{sem modificador} & S &	S &	N &	N \\ \hline
%		\textbf{\textit{private}} &	S &		N &	N &	N \\
%	\hline
%\end{tabular}
%\caption{Tabela de Modificadores de Acesso de Java}
%\end{table}
%================
%Example of figure
%\begin{figure}[H]
%\centering
%\includegraphics[scale=0.5]{img_1_1}
%\caption{\label{}Imagem -- Diagrama Conceitual de Java}
%\end{figure}
%================
%Example of acrostic text
%\begin{figure}[H]
%\begin{quote}
%\begin{alltt}
%[MY EXAMPLE]
%\end{alltt}
%\end{quote}
%\caption{Example of synonym application $-$ Paraphrased Text}
%\end{figure}
%
%----------------------------------------------------------------------------------------

%----------------------------------------------------------------------------------------
%	Abstract
%----------------------------------------------------------------------------------------
\begin{abstract}
ascasdas
\end{abstract}

%----------------------------------------------------------------------------------------
%	Introduction and Motivation
%----------------------------------------------------------------------------------------
\chapter{Introduction and Motivation}
lnmkm
%----------------------------------------------------------------------------------------
%	Description of own work
%----------------------------------------------------------------------------------------
\chapter{Generating Acrostics via Paraphrasing and Heursitic Search}

\section{Problem Definition}

\section{Modeling as Search Problem}

\section{Cost Measure}

\section{Operators}
most common according to the author

\subsection{Word Insertion or Deletion}
The idea around this operator is to insert words in the text or delete words from it, in order to insert new letters and accomplish the goal acrostic or to remove words and change the position of words inside the text. \par

To ilustrate the execution, consider the following text\footnote{This text was adapted for didactic purposes from \url{http://cornelia.siteware.ch/blog/wordpress/2008/11/03/sich-vorstellen-horverstehen}. Access in January, 2015}:

\begin{figure}[H]
\begin{quote}
\begin{alltt}
Ah ja, ich heisse Frederik Hoske und ich bin 13 Jahre. \textit{Ich kann nicht
vorstellen}, weil ich kaum Deutsch sprechen kann. Trotzdem versuche ich
es. Ich habe zwei Geschwister Mein Bruder der 16 Jahre alt ist und
meine Schweseter ist elf.
\end{alltt}
\end{quote}
\caption{Example of word insertion application $-$ Original Text}
\end{figure}

After inserting the word \emph{"mir"} in the sentence \emph{"Ich kann nicht vorstellen"} in the first line and after breaking a line right before \emph{"Trotzdem"} the algorithm can reach the acrostic \emph{amt}. Note that the insertion of \emph{"mir"} was crutial for the result, once that the letter \emph{m} was not there.

\begin{figure}[H]
\begin{quote}
\begin{alltt}
\textcolor{Blue}{A}h ja, ich heisse Frederik Hoske und ich bin 13 Jahre. \textit{Ich kann
\textcolor{Blue}{m}ir nicht vorstellen}, weil ich kaum Deutsch sprechen kann.
\textcolor{Blue}{T}rotzdem versuche ich es. Ich habe zwei Geschwister Mein Bruder der
16 Jahre alt ist und meine Schweseter ist elf.
\end{alltt}
\end{quote}
\caption{Example of word insertion application $-$ Paraphrased Text}
\end{figure}

The Word Insertion or Deletion operator takes as input a text. Then first it tries to insert a new word in each space and second tries to remove each word of the text. The condition to insert a new word \emph{w} in the \emph{i-th} space of the text is that \emph{w} has to fit the context around the \emph{i-th} space. It means that from the set of all possible words of the language, only a restricted subset can be inserted in this place. More specifically, the algorithm starts by taking for each space in the text \emph{n} words around it as context $-$ In our implementation in this context $n = 4$. This is a so called n-gram, an array of words. After this, the n-gram just taken is sent to the context database (which is in this implementation the Netspeak API \cite{Netspeak}), that returns the possible words that could be inserted in the required space. For each of these possible words a new version of the text is created with the word inside. \par

Analogously, for each word \emph{w} in the text a n-gram including the words around it is created $-$ In our implementation we take two words from each side, so here $n=5$. \emph{w} is then taken out of the n-gram, which is tested against the context database to check whether this n-gram is frequent enough in the language. If the answer is positive a new version of the text without \emph{w} is created. Our implementation allows the adjustment of the minimum frequency cited above, but we set it to zero, so a broader set of deletions is executed. \par

The queries to the context database are made in form of HTTP requests to the Netspeak web service using the Netspeak API. \par

\subsection{Synonyms}
The synonym operator has the goal of changing words in the text for other words, which have similar meaning. In general the operator takes a text as input and generates a set of new texts, in which each text has a word replaced by a synonym.

In order to perform the replacements it is required a synonym dictionary, which is know as thesaurus. In our implementation we used Open Thesaurus \cite{OpenThesuarus}, which is available for download for free. This data source is available as a plain text file, but as the dictionary is accessed many times during the execution of the algorithm, it soon becomes intractable to handle a text file as a database.

To solve this problem we decided to use a NoSQL database server \cite{NoSQL}, namely, Redis. Redis is an open source advanced key-value pair cache and store \cite{Redis}. Into the database server we load once the data from the thesaurus in a structured way where, every word is added as a key that points to a set of synonyms. Thus the application can easily and efficiently find similar terms for a given word only by accessing this key.

Naturally it is then required that the Redis server is running and listening to requests when the application runs, and that it has been once loaded by our script with the data from the dictionary.

\begin{figure}[H]
\begin{quote}
\begin{alltt}
[MY EXAMPLE]
\end{alltt}
\end{quote}
\caption{Example of synonym application $-$ Original Text}
\end{figure}

\begin{figure}[H]
\begin{quote}
\begin{alltt}
[MY EXAMPLE]
\end{alltt}
\end{quote}
\caption{Example of synonym application $-$ Paraphrased Text}
\end{figure}

The application of the Synonym Operation brings much more possibilities for new paraphrased versions of the original text. It happens because, when comparing with Word Insertion and Deletion, the probability of changing a word in the text with this operation is higher once it does not check the context around the changed word, therefore allowing many words to be replaced.

Consequently, the drawback is the considerable loss of quality in the results, in function of the fact that synonyms are strongly related to context, and some replacements may change substantially the meanings of the resulting texts.

\subsection{Line break}
The fastest and most basic operation is the line break. A line break can be applied in two cases:

\begin{itemize}
	\item After a word when the line length lies in the $[l_{min},l_{max}]$-window, 
	given by the line length constraints.
	\item After the end of a sentence.
\end{itemize} 
After performing a line break, the lines following the line break have
to be aligned again to satisfy the line length constraints.\\
For this task we apply a greedy word wrap algorithm, which works as follows: we split the text into words,
put the words on the line as long as there is free space, if there is no free space left, we continue with the next line.\\
When applying the greedy word wrap algorithm we have to ensure that
there is no word of length $> 20$ in the initial text. Otherwise it might happen, that the minimal line
length constraint is not fulfilled.\\
Identifying the end of a sentence in general is a difficult problem. One reason for this is that a period
might occur in several contexts, e.g. 

\begin{itemize}

	\item abbreviations (Prof., Dr., d.h., z.B., ...)
	
	\item ordinal numbers (der 26. April, Joseph II., 2. Auflage, ...)
	
	\item numbers (10.1312, 192.11301, ...)
	
\end{itemize}
Another issue is that there is a wide variety of punctuations which could mark the end of a sentence. These punctuations include question marks, exclamation marks, ellipses, semi-cola, cola.\\
To overcome these problems we make use of a sentence-splitter library, called Sentrick (cf. \cite{Sentrick}).


\subsection{Hyphenation}
 Related to the line break are hyphenations. A hyphenation is applicable if the line after hyphenating (and line breaking) has a length of at least $l_{min}=50$.\\ For hyphenating a word we employ a re-implementation of Knuth's hyphenation algorithm in TEX (cf. \cite{Hyphenation}). \\
After the hyphenation, the text following the hyphen has to be aligned again to satisfy the line length constraints.\\
Analog to the line break operation, in order to rearrange the lines we apply a greedy word wrap algorithm.













%----------------------------------------------------------------------------------------
%	Evaluation of the Results
%----------------------------------------------------------------------------------------
\chapter{Evaluation of the Results}

%----------------------------------------------------------------------------------------
%	Summary of Findings
%----------------------------------------------------------------------------------------
\chapter{Summary of Findings}
The algorithm described in this report is able to build acrostics with short words (we have achieved acrostics with 6 letters) in reasonable time. These acrostics have regular quality, in the sense that some paraphrasing operations are easyly perceived by the reader $-$ the wrong hyphenation is one of them. The use of synonyms without checking the context lowers the quality as well. Additionally, the algorithm can generate result in a few minutes for a good number of cases, what makes possible its use in some practical situations, aiding a process that was totally human so far. The review of the result by a human is although necessary. \par

//comment result here??\par

In despite of the reasonable results, we did not develop all the operators described in the reference paper (\cite{Stein}) mainly for project time reasons. A broader experimental discussion with a higher number of tests and a discussion about quality metrics on the text would be interesting as well, although it would be out of the scope of the project. \par

What should be noted in the problem of generating acrostics, is that the success depends highly on certain conditions of the text. When the target acrostic has uncommon letters, it becomes naturally more difficult to accomplish the result. This yields the need for more powerful operators, operators able to change more the structure of the text or insert new elements that aids the generation of the desired letters in the beginnnig of the lines. In this vein, a gramatical operator that could change swap the position of gramatical elements would be helpful, like ilustrated in the example below. \par

\begin{figure}[H]
\begin{quote}
\begin{alltt}
Wenn Sie wissen, was Sie wollen, wird es einfacher.
Wenn Sie, was Sie wollen, wissen, wird es einfacher.
Es wird einfacher, wenn Sie wissen, was Sie wollen.
Einfacher wird es, wenn Sie wissen, was Sie wollen.
\end{alltt}
\end{quote}
\caption{Example of possible additional operator}
\end{figure}

Other possible improvement is the development of a non-empirical method for defining costs for each operation. The choice of such parameters seems to be vital for the success of the search method. According to \cite[p.~2023]{Stein}, a bad choice may lead to a breadth-first, while the desired is a depth-first search if the computing resources are scarce. The time consumed by requests to the n-gram web service are also sources of problems for such environments. But in this case the implemenentation of a n-gram database locally may smooth the problem. \par

The use of the Netspeak API seems to be another issue, once it does not produce many options for inserting or removing words. A solution would be the implementation of the complete Google n-gram database locally. Even though the use of context in form of n-gram are sometimes too restrictive. This could be therefore a discussion for future work.


%----------------------------------------------------------------------------------------
%	References
%----------------------------------------------------------------------------------------
\begin{thebibliography}{1}
\bibitem{Stein}
	Benno Stein, Matthias Hagen, and Christof Bräutigam. \emph{Generating Acrostics via Paraphrasing and Heuristic Search}. \\
	In Junichi Tsujii and Jan Hajic, editors, 25th International Conference on Computational Linguistics (COLING 14), pages 2018-2029, August 2014. Association for Computational Linguistics. 
\bibitem{Netspeak}
	Martin Potthast, Martin Trenkmann, and Benno Stein.
	\emph{Netspeak: Assisting Writers in Choosing Words}. \\
	In Cathal Gurrin et al, editors, Advances in Information Retrieval. 32nd European Conference on Information Retrieval (ECIR 10) volume 5993 of Lecture Notes in Computer Science, pages 672, Berlin Heidelberg New York, March 2010. Springer.
\bibitem{OpenThesuarus}
	\emph{Synonyme - OpenThesaurus - Deutscher Thesaurus}.
	Available on: $<$\url{https://www.openthesaurus.de}$>$.
	Accessed in: January 2015.
\bibitem{NoSQL}
	Jing Han; Haihong, E.; Guan Le; Jian Du. \emph{Survey on NoSQL database}. Pervasive Computing and Applications (ICPCA), 2011 6th International Conference on, pp.363,366, 26-28 October 2011.
\bibitem{Redis}
	\emph{Redis}.
	Available on: $<$\url{http://redis.io}$>$.
	Accessed in: January 2015.
\bibitem{Sentrick}
\url{http://sourceforge.net/projects/sentrick/}
\bibitem{Hyphenation}
\url{http://sourceforge.net/projects/texhyphj/}
\end{thebibliography}

%----------------------------------------------------------------------------------------
%	Appendix
%----------------------------------------------------------------------------------------
\appendix
\chapter{Appendix}


\end{document}
